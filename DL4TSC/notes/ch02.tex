\chapter{PyTorch 入门}
\section{训练前馈神经网络}
前馈神经网络，又称多层感知器(MLP)，是最简单的人工神经网络类型之一。数据从输入层流向输出层，经过隐藏层，中间没有任何循环。在这种类型的神经网络中，一层中的所有隐藏单元都连接到下一层的单元。
\section{训练循环神经网络}
循环神经网络(RNN)是一类神经网络，对于涉及序列数据的任务特别有效，例如时间序列预测和自然语言处理。RNN 通过隐藏层来使用序列信息，该隐藏层能够将信息从序列中的一个步骤传递到下一个步骤。
\section{训练 LSTM 神经网络}
RNN 存在一个基本问题，即“梯度消失”，由于神经网络反向传播的性质，随着序列变长，早期输入对整体误差的影响会急剧减小。这在存在长期依赖关系（即未来输出取决于更早的输入）的序列处理任务中尤其成问题。

为了解决这个问题，LSTM 网络应运而生。与 RNN 相比，LSTM 的每个单元都采用了更复杂的内部结构。具体来说，LSTM 能够根据称为单元的内部结构来决定丢弃或存储哪些信息。该单元使用门（输入门、遗忘门和输出门）来控制信息流入和流出单元。这有助于维护和操纵“长期”信息，从而缓解梯度消失问题。
\section{训练卷积神经网络}
卷积神经网络(CNN)是一类神经网络，对于涉及网格状输入数据（例如图像、音频频谱图，甚至某些类型的时间序列数据）的任务特别有效。CNN 的核心思想是使用卷积滤波器（也称为核）对输入数据应用卷积运算，卷积滤波器在输入数据上滑动以产生输出特征图。